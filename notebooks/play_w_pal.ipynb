{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the PAL algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something interesting: https://github.com/VitoChan1/PAL-on-Adder-DSE/blob/master/PAL.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the paper (PAL: An Active Learning Approach to the Multi-Objective Optimization Problem form the Puschel group at ETH)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* error bounds based on hypervolume error\n",
    "* response surface methods for unevaluated designs. Best so far: PareEGO also uses GP\n",
    "* scalariztion: without assumptions like convexity not all solutions can be recovered\n",
    "\n",
    "* uncertainity captured with hyperparameter, there is some scaling parameter beta that determines which fraction of the variance is used. \n",
    "* then classified as pareto optimal if the pessimistic bound is not dominated by the optimistic outcome of any other point\n",
    "* if the optimisitc bound is dominated by the pessimistic bound of any other point, then not pareto optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pareto_optimal(scores: np.array) -> np.array:\n",
    "    size = scores.shape[0]\n",
    "    ids = np.arange(size)\n",
    "    pareto_front = np.ones(size, dtype=bool)\n",
    "    for j in range(size):\n",
    "        # Check if our 'i' point is dominated by our 'j' point\n",
    "        if all(scores[j] >= scores[i]) and any(scores[j] > scores[i]):\n",
    "            # j dominates i. Label 'i' point as dominant\n",
    "            pareto_front[i] = 0\n",
    "            break\n",
    "    # Return ids of pareto front\n",
    "    return ids[pareto_front]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use PyGMO as they have spent more thought into how to implement this: \n",
    "\n",
    "https://esa.github.io/pygmo/documentation/hypervolume.html\n",
    "\n",
    "Implements, e.g., WFG (https://ieeexplore.ieee.org/document/5766730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmo as pg \n",
    "from typing import Union, Iterable\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypervolume(pareto_front: np.array, reference_vector: np.array) -> float: \n",
    "    hyp = pg.hypervolume(pareto_front) \n",
    "    volume = hyp.compute(reference_vector) # uses 'auto' algorithm\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_gp_predictions(gps: Iterable, x_train: np.array, y_train: np.array, x_input: np.array) -> Union[np.array, np.array]: \n",
    "    # get the GP predictions, for generality, we will assume a list of GPs\n",
    "    # one GP per target\n",
    "    mus = []\n",
    "    stds = []\n",
    "    \n",
    "    # train one GP per target\n",
    "    for i, gp in enumerate(gps): \n",
    "        gp.fit(x_train, y_train[:,i])\n",
    "        mu, std = gp.predict(x_input, return_std=True)\n",
    "        mus.append(mu.reshape(-1,1))\n",
    "        stds.append(std.reshape(-1,1))\n",
    "    \n",
    "        \n",
    "    return np.hstack(mus), np.hstack(stds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_uncertainity_region(mu: float, std: float, beta_sqrt: float): \n",
    "    low_lim, high_lim = mu -  beta_sqrt * std, mu +   beta_sqrt * std\n",
    "    return low_lim, high_lim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_uncertainity_regions(mus: np.array, stds: np.array, beta_sqrt: float): \n",
    "    low_lims, high_lims = [], []\n",
    "    for i in range(0, mus.shape[1]):\n",
    "        low_lim, high_lim = _get_uncertainity_region(mus[:,i], stds[:,i], beta_sqrt)\n",
    "        low_lims.append(low_lim.reshape(-1,1))\n",
    "        high_lims.append(high_lim.reshape(-1,1))\n",
    "        \n",
    "    return np.hstack(low_lims), np.hstack(high_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _union_single_feat(lows: Iterable, ups: Iterable, new_lows: Iterable, new_ups: Iterable) -> Union[Iterable, Iterable]:\n",
    "    out_lows = []\n",
    "    out_ups = []\n",
    "    for i in range(0,len(lows)):\n",
    "        if (new_lows[i] > ups[i]) or (new_ups[i] < lows[i]) or (lows[i] + ups[i] == 0):\n",
    "            out_lows.append(0)\n",
    "            out_ups.append(0)\n",
    "        else:\n",
    "            out_lows.append(max(lows[i], new_lows[i]))\n",
    "            out_ups.append(min(ups[i],new_ups[i]))\n",
    "            \n",
    "    return np.array(out_lows), np.array(out_ups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _union(lows: Iterable, ups: Iterable, new_lows: Iterable, new_ups: Iterable) -> Union[Iterable, Iterable]:\n",
    "    # iterative intersection, eq. 6 in paper, make uncertainity regions smaller\n",
    "    out_lows = []\n",
    "    out_ups = []\n",
    "    for i in range(0, lows.shape[1]):\n",
    "        l, u = _union_single_feat(lows[:,i], ups[:,i], new_lows[:,i], new_ups[:,i])\n",
    "        out_lows.append(l.reshape(-1,1))\n",
    "        out_ups.append(u.reshape(-1,1))\n",
    "    return np.hstack(out_lows), np.hstack(out_ups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sampled(mus, stds, sampled, y_input):\n",
    "    # this is kinda inefficient, better use some kind of indexing \n",
    "    for i in range(0,len(mus)):\n",
    "        if (sampled[i] == 1):\n",
    "            mus[i, :] = y_input[i, :]\n",
    "            \n",
    "            # ToDo: is this true? \n",
    "            stds[i, :] = 0\n",
    "            \n",
    "    return mus, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pareto_classify(pareto_optimal_0: list, not_pareto_optimal_0: list, unclassified_0: list, rectangle_lows: np.array, rectangle_ups: np.array, x_input: np.array, epsilon: float) -> Union[list, list, list]:\n",
    "    pareto_optimal_t = pareto_optimal_0\n",
    "    not_pareto_optimal_t = not_pareto_optimal_0\n",
    "    unclassified_t = unclassified_0\n",
    "    \n",
    "    # loop over samples \n",
    "    for i in range(0, len(x_input)):\n",
    "        if (unclassified_t[i] == 1):\n",
    "            pareto = True\n",
    "            nonpareto = False\n",
    "            \n",
    "            # At iteration t, the points in Pt−1 and Nt−1 keep their classification. The only points x to be reclassified are those in Ut−1 , done as follows\n",
    "            \n",
    "            # If the pessimistic outcome min(Rt(x)) of x is not dominated by the optimistic outcome max(Rt(x )) of any other point (up to a shift of ε by both),\n",
    "            if all(rectangle_lows[i] * (1 + epsilon) <= rectangle_ups[i] * (1 - epsilon)):\n",
    "                pareto = False\n",
    "                \n",
    "            # If the optimistic outcome max(Rt(x)) of x is dominated by the pessimistic outcome min(Rt(x′)) of any x′ (up to a shift of ε by both),    \n",
    "            if all(rectangle_ups[i] * (1 - epsilon) <= rectangle_lows[i] * (1 + epsilon)): \n",
    "                nonpareto = True\n",
    "            \n",
    "            # All other points remain unclassified.\n",
    "            if pareto:\n",
    "                pareto_optimal_t[i] = 1\n",
    "                unclassified_t[i] = 0\n",
    "            elif nonpareto:\n",
    "                not_pareto_optimal_t[i] = 1\n",
    "                unclassified_t[i] = 0\n",
    "                \n",
    "    return pareto_optimal_t, not_pareto_optimal_t, unclassified_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample(rectangle_lows, rectangle_ups, pareto_optimal_t, non_pareto_optimal_t, unclassified_t, sampled, x_input, y_input, x_train, y_train):\n",
    "    maxwt = 0\n",
    "    maxid = -1\n",
    "    \n",
    "    for i in range(0,len(x_input)):\n",
    "        # Among the points x ∈ Pt ∪ Ut, the one with the largest wt(x) is chosen as the next sample xt to be evaluated.\n",
    "        # Intuitively, this rule biases the sampling towards exploring, and thus improving the model for, the points most likely to be Pareto-optimal.\n",
    "        if ((unclassified_t[i] == 1) or (pareto_optimal_t[i] == 1)) and not(sampled[i] == 1):\n",
    "            # weight is the length of the diagonal of the uncertainity region\n",
    "            wt = np.linalg.norm(rectangle_ups[i,:] - rectangle_lows[i,:])\n",
    "            if maxid == -1:\n",
    "                maxwt = wt\n",
    "                maxid = i\n",
    "            # the point with the largest weight is chosen as the next sample\n",
    "            elif wt > maxwt:\n",
    "                maxwt = wt\n",
    "                maxid = i\n",
    "                \n",
    "    x_train = np.insert(x_train, x_train.shape[0], x_input[maxid], axis = 0)\n",
    "    y_train = np.insert(y_train, y_train.shape[0], y_input[maxid], axis = 0)\n",
    "    \n",
    "    sampled[maxid] = 1\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I assume that we exhaustively sampled, so we can provide y directly as input. Otherwise, there will be a sampling function that can return y\n",
    "def pal(gps: list, x_train: np.array, y_train: np.array, x_input: np.array, y_input: np.array, hv_reference: Iterable = [10, 10], delta: float = 0.05, epsilon: float = 0.001, iterations: int = 100):\n",
    "    # x_input is the E set in the PAL paper \n",
    "    # the models for now assume the sklearn API, i.e., there should be a fit function \n",
    "    assert y_train.shape[1] == len(hv_reference)\n",
    "   \n",
    "    # initalize binary list to keep track of the different sets\n",
    "    # in the beginning, nothing is selected = everything is unclassified\n",
    "    pareto_optimal_0 = [0] * len(x_input)\n",
    "    not_pareto_optimal_0 = [0] * len(x_input)\n",
    "    unclassified_0 = [1] * len(x_input) \n",
    "    sampled = [0] * len(x_input)\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "            '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    \n",
    "    logger.info(\"Starting now the PAL loop\")\n",
    "    logger.debug(\"Will use the following settings\")\n",
    "    logger.debug(\"epsilon: {}, delta: {}, iterations: {}\".format(epsilon, delta, iterations))\n",
    "    logger.debug(\"x_train shape: {}, y_train shape: {}\".format(x_train.shape, y_train.shape))\n",
    "\n",
    "    # stop when all points are classified \n",
    "    while (np.sum(unclassified_0) > 0) and (iteration <= iterations):\n",
    "        iteration += 1\n",
    "        logger.debug(\"Starting iteration {}\".format(iteration))\n",
    "        \n",
    "        # STEP 1: modeling (train and predict using GPR, one GP per target)\n",
    "        logger.debug(\"Starting modeling step, fitting the GPs\")\n",
    "        mus, stds = _get_gp_predictions(gps, x_train, y_train, x_input)\n",
    "    \n",
    "        # update scaling parameter β\n",
    "        # which is achieved by choosing βt = 2 log(n|E|π2t2/(6δ)).\n",
    "        # n: number of objectives (y_input.shape[1])\n",
    "        beta = 2 * np.log(y_input.shape[1] * len(x_input) * np.square(np.pi) * np.square(iteration) / (6 * delta))\n",
    "        logger.debug(\"Scaling parameter beta at the current iteration is {}\".format(beta))\n",
    "        \n",
    "        logger.debug(\"mean array shape: {}, std array shape: {}\".format(mus.shape, stds.shape))\n",
    "        \n",
    "        # if point is sampled we know the mu and have no epistemic uncertainity    \n",
    "        mus, stds = _update_sampled(mus, stds, sampled, y_input)\n",
    "        \n",
    "        logger.debug(\"mean array shape: {}, std array shape: {}\".format(mus.shape, stds.shape))\n",
    "        \n",
    "        # get the uncertainity rectangles, sqrt only once here for efficiency\n",
    "        lows, ups = _get_uncertainity_regions(mus, stds, np.sqrt(beta))\n",
    "        \n",
    "        logger.debug(\"lows shape {}, ups shape {}\".format(lows.shape, ups.shape))\n",
    "        \n",
    "        \n",
    "        if iteration == 1: \n",
    "            # initialization\n",
    "            rectangle_lows, rectangle_ups = lows, ups\n",
    "        else:\n",
    "            rectangle_lows, rectangle_ups = _union(rectangle_lows, rectangle_ups, lows, ups)\n",
    "            \n",
    "        \n",
    "        logger.debug(\"rectangle lows shape {}, rectangle ups shape {}\".format(rectangle_lows.shape, rectangle_ups.shape))\n",
    "        # pareto classification\n",
    "        # update lists \n",
    "        pareto_optimal_t, not_pareto_optimal_t, unclassified_t = _pareto_classify(pareto_optimal_0, \n",
    "                                                                                  not_pareto_optimal_0, \n",
    "                                                                                  unclassified_0, \n",
    "                                                                                  rectangle_lows, \n",
    "                                                                                  rectangle_ups, x_input, epsilon)\n",
    "\n",
    "        \n",
    "        # sampling from x_input \n",
    "        # ToDo: sample multiple structures\n",
    "        x_train, y_train, sampled = _sample(rectangle_lows, rectangle_ups, pareto_optimal_t, not_pareto_optimal_t, unclassified_t, sampled, x_input, y_input, x_train, y_train)\n",
    "        pareto_optimal_0, not_pareto_optimal_0, unclassified_0 = pareto_optimal_t, not_pareto_optimal_t, unclassified_t\n",
    "          \n",
    "        logger.info('Summary at current iteration: Pareto optimal {}, not pareto optimal {}, unclassified {}'.format(np.array(pareto_optimal_0).sum(), \n",
    "                                                                                                                      np.array(not_pareto_optimal_0).sum(), \n",
    "                                                                                                                      np.array(unclassified_0).sum()))\n",
    "       \n",
    "        optimal_indices= np.where(np.array(pareto_optimal_0) == 1)[0]\n",
    "\n",
    "        if len(optimal_indices) > 0:\n",
    "            hypervolume = get_hypervolume(y_input[optimal_indices], hv_reference) \n",
    "        else: \n",
    "            hypervolume = np.nan\n",
    "        \n",
    "        logger.info('Current hypervolume {:.2f}'.format(hypervolume))\n",
    "        \n",
    "    return pareto_optimal_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "import joblib\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dispersant_screener.definitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../data'\n",
    "TRAIN_SIZE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_factorial = pd.read_csv(os.path.join(DATADIR, 'full_fact.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_full_factorial[FEATURES]\n",
    "y = df_full_factorial[TARGETS]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.251920767607366"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hypervolume(y_test, [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "virial_model = GaussianProcessRegressor(kernel=Matern(), normalize_y=True, n_restarts_optimizer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbs_model = GaussianProcessRegressor(kernel=Matern(), normalize_y=True, n_restarts_optimizer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = [virial_model, gibbs_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-02 20:52:21,465 root         INFO     Starting now the PAL loop\n",
      "2020-06-02 20:52:21,465 root         INFO     Starting now the PAL loop\n",
      "2020-06-02 20:52:21,465 root         INFO     Starting now the PAL loop\n",
      "2020-06-02 20:52:21,465 root         INFO     Starting now the PAL loop\n",
      "2020-06-02 20:52:21,465 root         INFO     Starting now the PAL loop\n",
      "2020-06-02 20:52:21,468 root         DEBUG    Will use the following settings\n",
      "2020-06-02 20:52:21,468 root         DEBUG    Will use the following settings\n",
      "2020-06-02 20:52:21,468 root         DEBUG    Will use the following settings\n",
      "2020-06-02 20:52:21,468 root         DEBUG    Will use the following settings\n",
      "2020-06-02 20:52:21,468 root         DEBUG    Will use the following settings\n",
      "2020-06-02 20:52:21,471 root         DEBUG    epsilon: 0.001, delta: 0.05, iterations: 100\n",
      "2020-06-02 20:52:21,471 root         DEBUG    epsilon: 0.001, delta: 0.05, iterations: 100\n",
      "2020-06-02 20:52:21,471 root         DEBUG    epsilon: 0.001, delta: 0.05, iterations: 100\n",
      "2020-06-02 20:52:21,471 root         DEBUG    epsilon: 0.001, delta: 0.05, iterations: 100\n",
      "2020-06-02 20:52:21,471 root         DEBUG    epsilon: 0.001, delta: 0.05, iterations: 100\n",
      "2020-06-02 20:52:21,474 root         DEBUG    x_train shape: (1562, 19), y_train shape: (1562, 2)\n",
      "2020-06-02 20:52:21,474 root         DEBUG    x_train shape: (1562, 19), y_train shape: (1562, 2)\n",
      "2020-06-02 20:52:21,474 root         DEBUG    x_train shape: (1562, 19), y_train shape: (1562, 2)\n",
      "2020-06-02 20:52:21,474 root         DEBUG    x_train shape: (1562, 19), y_train shape: (1562, 2)\n",
      "2020-06-02 20:52:21,474 root         DEBUG    x_train shape: (1562, 19), y_train shape: (1562, 2)\n",
      "2020-06-02 20:52:21,477 root         DEBUG    Starting iteration 1\n",
      "2020-06-02 20:52:21,477 root         DEBUG    Starting iteration 1\n",
      "2020-06-02 20:52:21,477 root         DEBUG    Starting iteration 1\n",
      "2020-06-02 20:52:21,477 root         DEBUG    Starting iteration 1\n",
      "2020-06-02 20:52:21,477 root         DEBUG    Starting iteration 1\n",
      "2020-06-02 20:52:21,480 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:21,480 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:21,480 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:21,480 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:21,480 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:362: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "2020-06-02 20:52:53,014 root         DEBUG    Scaling parameter beta at the current iteration is 23.081884174012316\n",
      "2020-06-02 20:52:53,014 root         DEBUG    Scaling parameter beta at the current iteration is 23.081884174012316\n",
      "2020-06-02 20:52:53,014 root         DEBUG    Scaling parameter beta at the current iteration is 23.081884174012316\n",
      "2020-06-02 20:52:53,014 root         DEBUG    Scaling parameter beta at the current iteration is 23.081884174012316\n",
      "2020-06-02 20:52:53,014 root         DEBUG    Scaling parameter beta at the current iteration is 23.081884174012316\n",
      "2020-06-02 20:52:53,018 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,018 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,018 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,018 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,018 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,023 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,023 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,023 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,023 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,023 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:52:53,029 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,029 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,029 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,029 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,029 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,033 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,033 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,033 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,033 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,033 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:52:53,102 root         INFO     Summary at current iteration: Pareto optimal 1, not pareto optimal 0, unclassified 1562\n",
      "2020-06-02 20:52:53,102 root         INFO     Summary at current iteration: Pareto optimal 1, not pareto optimal 0, unclassified 1562\n",
      "2020-06-02 20:52:53,102 root         INFO     Summary at current iteration: Pareto optimal 1, not pareto optimal 0, unclassified 1562\n",
      "2020-06-02 20:52:53,102 root         INFO     Summary at current iteration: Pareto optimal 1, not pareto optimal 0, unclassified 1562\n",
      "2020-06-02 20:52:53,102 root         INFO     Summary at current iteration: Pareto optimal 1, not pareto optimal 0, unclassified 1562\n",
      "2020-06-02 20:52:53,110 root         INFO     Current hypervolume 206.35\n",
      "2020-06-02 20:52:53,110 root         INFO     Current hypervolume 206.35\n",
      "2020-06-02 20:52:53,110 root         INFO     Current hypervolume 206.35\n",
      "2020-06-02 20:52:53,110 root         INFO     Current hypervolume 206.35\n",
      "2020-06-02 20:52:53,110 root         INFO     Current hypervolume 206.35\n",
      "2020-06-02 20:52:53,115 root         DEBUG    Starting iteration 2\n",
      "2020-06-02 20:52:53,115 root         DEBUG    Starting iteration 2\n",
      "2020-06-02 20:52:53,115 root         DEBUG    Starting iteration 2\n",
      "2020-06-02 20:52:53,115 root         DEBUG    Starting iteration 2\n",
      "2020-06-02 20:52:53,115 root         DEBUG    Starting iteration 2\n",
      "2020-06-02 20:52:53,119 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:53,119 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:53,119 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:53,119 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:52:53,119 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:362: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "2020-06-02 20:53:28,737 root         DEBUG    Scaling parameter beta at the current iteration is 25.854472896252098\n",
      "2020-06-02 20:53:28,737 root         DEBUG    Scaling parameter beta at the current iteration is 25.854472896252098\n",
      "2020-06-02 20:53:28,737 root         DEBUG    Scaling parameter beta at the current iteration is 25.854472896252098\n",
      "2020-06-02 20:53:28,737 root         DEBUG    Scaling parameter beta at the current iteration is 25.854472896252098\n",
      "2020-06-02 20:53:28,737 root         DEBUG    Scaling parameter beta at the current iteration is 25.854472896252098\n",
      "2020-06-02 20:53:28,742 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,742 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,742 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,742 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,742 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,745 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,745 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,745 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,745 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,745 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:53:28,751 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,751 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,751 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,751 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,751 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,772 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,772 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,772 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,772 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,772 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:53:28,825 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:53:28,825 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:53:28,825 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:53:28,825 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:53:28,825 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:53:28,830 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:53:28,830 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:53:28,830 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:53:28,830 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:53:28,830 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:53:28,834 root         DEBUG    Starting iteration 3\n",
      "2020-06-02 20:53:28,834 root         DEBUG    Starting iteration 3\n",
      "2020-06-02 20:53:28,834 root         DEBUG    Starting iteration 3\n",
      "2020-06-02 20:53:28,834 root         DEBUG    Starting iteration 3\n",
      "2020-06-02 20:53:28,834 root         DEBUG    Starting iteration 3\n",
      "2020-06-02 20:53:28,837 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:53:28,837 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:53:28,837 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:53:28,837 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:53:28,837 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:362: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "2020-06-02 20:54:21,616 root         DEBUG    Scaling parameter beta at the current iteration is 27.476333328684756\n",
      "2020-06-02 20:54:21,616 root         DEBUG    Scaling parameter beta at the current iteration is 27.476333328684756\n",
      "2020-06-02 20:54:21,616 root         DEBUG    Scaling parameter beta at the current iteration is 27.476333328684756\n",
      "2020-06-02 20:54:21,616 root         DEBUG    Scaling parameter beta at the current iteration is 27.476333328684756\n",
      "2020-06-02 20:54:21,616 root         DEBUG    Scaling parameter beta at the current iteration is 27.476333328684756\n",
      "2020-06-02 20:54:21,619 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,619 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,619 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,619 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,619 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,623 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,623 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,623 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,623 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,623 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:21,627 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,627 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,627 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,627 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,627 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,647 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,647 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,647 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,647 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,647 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:21,702 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:54:21,702 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:54:21,702 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:54:21,702 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:54:21,702 root         INFO     Summary at current iteration: Pareto optimal 4, not pareto optimal 0, unclassified 1559\n",
      "2020-06-02 20:54:21,707 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:54:21,707 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:54:21,707 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:54:21,707 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:54:21,707 root         INFO     Current hypervolume 215.14\n",
      "2020-06-02 20:54:21,712 root         DEBUG    Starting iteration 4\n",
      "2020-06-02 20:54:21,712 root         DEBUG    Starting iteration 4\n",
      "2020-06-02 20:54:21,712 root         DEBUG    Starting iteration 4\n",
      "2020-06-02 20:54:21,712 root         DEBUG    Starting iteration 4\n",
      "2020-06-02 20:54:21,712 root         DEBUG    Starting iteration 4\n",
      "2020-06-02 20:54:21,716 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:21,716 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:21,716 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:21,716 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:21,716 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:362: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "2020-06-02 20:54:42,977 root         DEBUG    Scaling parameter beta at the current iteration is 28.62706161849188\n",
      "2020-06-02 20:54:42,977 root         DEBUG    Scaling parameter beta at the current iteration is 28.62706161849188\n",
      "2020-06-02 20:54:42,977 root         DEBUG    Scaling parameter beta at the current iteration is 28.62706161849188\n",
      "2020-06-02 20:54:42,977 root         DEBUG    Scaling parameter beta at the current iteration is 28.62706161849188\n",
      "2020-06-02 20:54:42,977 root         DEBUG    Scaling parameter beta at the current iteration is 28.62706161849188\n",
      "2020-06-02 20:54:42,981 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,981 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,981 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,981 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,981 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,984 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,984 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,984 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,984 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,984 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:54:42,989 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:42,989 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:42,989 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:42,989 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:42,989 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:54:43,008 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:43,008 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:43,008 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:43,008 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:43,008 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:54:43,058 root         INFO     Summary at current iteration: Pareto optimal 5, not pareto optimal 0, unclassified 1558\n",
      "2020-06-02 20:54:43,058 root         INFO     Summary at current iteration: Pareto optimal 5, not pareto optimal 0, unclassified 1558\n",
      "2020-06-02 20:54:43,058 root         INFO     Summary at current iteration: Pareto optimal 5, not pareto optimal 0, unclassified 1558\n",
      "2020-06-02 20:54:43,058 root         INFO     Summary at current iteration: Pareto optimal 5, not pareto optimal 0, unclassified 1558\n",
      "2020-06-02 20:54:43,058 root         INFO     Summary at current iteration: Pareto optimal 5, not pareto optimal 0, unclassified 1558\n",
      "2020-06-02 20:54:43,061 root         INFO     Current hypervolume 224.81\n",
      "2020-06-02 20:54:43,061 root         INFO     Current hypervolume 224.81\n",
      "2020-06-02 20:54:43,061 root         INFO     Current hypervolume 224.81\n",
      "2020-06-02 20:54:43,061 root         INFO     Current hypervolume 224.81\n",
      "2020-06-02 20:54:43,061 root         INFO     Current hypervolume 224.81\n",
      "2020-06-02 20:54:43,065 root         DEBUG    Starting iteration 5\n",
      "2020-06-02 20:54:43,065 root         DEBUG    Starting iteration 5\n",
      "2020-06-02 20:54:43,065 root         DEBUG    Starting iteration 5\n",
      "2020-06-02 20:54:43,065 root         DEBUG    Starting iteration 5\n",
      "2020-06-02 20:54:43,065 root         DEBUG    Starting iteration 5\n",
      "2020-06-02 20:54:43,068 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:43,068 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:43,068 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:43,068 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:54:43,068 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "2020-06-02 20:55:01,797 root         DEBUG    Scaling parameter beta at the current iteration is 29.519635823748718\n",
      "2020-06-02 20:55:01,797 root         DEBUG    Scaling parameter beta at the current iteration is 29.519635823748718\n",
      "2020-06-02 20:55:01,797 root         DEBUG    Scaling parameter beta at the current iteration is 29.519635823748718\n",
      "2020-06-02 20:55:01,797 root         DEBUG    Scaling parameter beta at the current iteration is 29.519635823748718\n",
      "2020-06-02 20:55:01,797 root         DEBUG    Scaling parameter beta at the current iteration is 29.519635823748718\n",
      "2020-06-02 20:55:01,802 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,802 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,802 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,802 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,802 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,807 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,807 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,807 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,807 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,807 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:01,811 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,811 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,811 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,811 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,811 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,834 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,834 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,834 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,834 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,834 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:01,885 root         INFO     Summary at current iteration: Pareto optimal 7, not pareto optimal 0, unclassified 1556\n",
      "2020-06-02 20:55:01,885 root         INFO     Summary at current iteration: Pareto optimal 7, not pareto optimal 0, unclassified 1556\n",
      "2020-06-02 20:55:01,885 root         INFO     Summary at current iteration: Pareto optimal 7, not pareto optimal 0, unclassified 1556\n",
      "2020-06-02 20:55:01,885 root         INFO     Summary at current iteration: Pareto optimal 7, not pareto optimal 0, unclassified 1556\n",
      "2020-06-02 20:55:01,885 root         INFO     Summary at current iteration: Pareto optimal 7, not pareto optimal 0, unclassified 1556\n",
      "2020-06-02 20:55:01,888 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:01,888 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:01,888 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:01,888 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:01,888 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:01,892 root         DEBUG    Starting iteration 6\n",
      "2020-06-02 20:55:01,892 root         DEBUG    Starting iteration 6\n",
      "2020-06-02 20:55:01,892 root         DEBUG    Starting iteration 6\n",
      "2020-06-02 20:55:01,892 root         DEBUG    Starting iteration 6\n",
      "2020-06-02 20:55:01,892 root         DEBUG    Starting iteration 6\n",
      "2020-06-02 20:55:01,895 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:01,895 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:01,895 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:01,895 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:01,895 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:362: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "2020-06-02 20:55:16,575 root         DEBUG    Scaling parameter beta at the current iteration is 30.248922050924538\n",
      "2020-06-02 20:55:16,575 root         DEBUG    Scaling parameter beta at the current iteration is 30.248922050924538\n",
      "2020-06-02 20:55:16,575 root         DEBUG    Scaling parameter beta at the current iteration is 30.248922050924538\n",
      "2020-06-02 20:55:16,575 root         DEBUG    Scaling parameter beta at the current iteration is 30.248922050924538\n",
      "2020-06-02 20:55:16,575 root         DEBUG    Scaling parameter beta at the current iteration is 30.248922050924538\n",
      "2020-06-02 20:55:16,578 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,578 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,578 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,578 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,578 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,581 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,581 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,581 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,581 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,581 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:16,586 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,586 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,586 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,586 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,586 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,605 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,605 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,605 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,605 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,605 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:16,655 root         INFO     Summary at current iteration: Pareto optimal 8, not pareto optimal 0, unclassified 1555\n",
      "2020-06-02 20:55:16,655 root         INFO     Summary at current iteration: Pareto optimal 8, not pareto optimal 0, unclassified 1555\n",
      "2020-06-02 20:55:16,655 root         INFO     Summary at current iteration: Pareto optimal 8, not pareto optimal 0, unclassified 1555\n",
      "2020-06-02 20:55:16,655 root         INFO     Summary at current iteration: Pareto optimal 8, not pareto optimal 0, unclassified 1555\n",
      "2020-06-02 20:55:16,655 root         INFO     Summary at current iteration: Pareto optimal 8, not pareto optimal 0, unclassified 1555\n",
      "2020-06-02 20:55:16,659 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:16,659 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:16,659 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:16,659 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:16,659 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:16,663 root         DEBUG    Starting iteration 7\n",
      "2020-06-02 20:55:16,663 root         DEBUG    Starting iteration 7\n",
      "2020-06-02 20:55:16,663 root         DEBUG    Starting iteration 7\n",
      "2020-06-02 20:55:16,663 root         DEBUG    Starting iteration 7\n",
      "2020-06-02 20:55:16,663 root         DEBUG    Starting iteration 7\n",
      "2020-06-02 20:55:16,667 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:16,667 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:16,667 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:16,667 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:16,667 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "2020-06-02 20:55:33,941 root         DEBUG    Scaling parameter beta at the current iteration is 30.86552477023357\n",
      "2020-06-02 20:55:33,941 root         DEBUG    Scaling parameter beta at the current iteration is 30.86552477023357\n",
      "2020-06-02 20:55:33,941 root         DEBUG    Scaling parameter beta at the current iteration is 30.86552477023357\n",
      "2020-06-02 20:55:33,941 root         DEBUG    Scaling parameter beta at the current iteration is 30.86552477023357\n",
      "2020-06-02 20:55:33,941 root         DEBUG    Scaling parameter beta at the current iteration is 30.86552477023357\n",
      "2020-06-02 20:55:33,945 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,945 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,945 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,945 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,945 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,949 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,949 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,949 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,949 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,949 root         DEBUG    mean array shape: (1563, 2), std array shape: (1563, 2)\n",
      "2020-06-02 20:55:33,953 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,953 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,953 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,953 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,953 root         DEBUG    lows shape (1563, 2), ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,975 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,975 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,975 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,975 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:33,975 root         DEBUG    rectangle lows shape (1563, 2), rectangle ups shape (1563, 2)\n",
      "2020-06-02 20:55:34,024 root         INFO     Summary at current iteration: Pareto optimal 9, not pareto optimal 0, unclassified 1554\n",
      "2020-06-02 20:55:34,024 root         INFO     Summary at current iteration: Pareto optimal 9, not pareto optimal 0, unclassified 1554\n",
      "2020-06-02 20:55:34,024 root         INFO     Summary at current iteration: Pareto optimal 9, not pareto optimal 0, unclassified 1554\n",
      "2020-06-02 20:55:34,024 root         INFO     Summary at current iteration: Pareto optimal 9, not pareto optimal 0, unclassified 1554\n",
      "2020-06-02 20:55:34,024 root         INFO     Summary at current iteration: Pareto optimal 9, not pareto optimal 0, unclassified 1554\n",
      "2020-06-02 20:55:34,028 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:34,028 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:34,028 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:34,028 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:34,028 root         INFO     Current hypervolume 241.44\n",
      "2020-06-02 20:55:34,031 root         DEBUG    Starting iteration 8\n",
      "2020-06-02 20:55:34,031 root         DEBUG    Starting iteration 8\n",
      "2020-06-02 20:55:34,031 root         DEBUG    Starting iteration 8\n",
      "2020-06-02 20:55:34,031 root         DEBUG    Starting iteration 8\n",
      "2020-06-02 20:55:34,031 root         DEBUG    Starting iteration 8\n",
      "2020-06-02 20:55:34,035 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:34,035 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:34,035 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:34,035 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "2020-06-02 20:55:34,035 root         DEBUG    Starting modeling step, fitting the GPs\n",
      "/Users/kevinmaikjablonka/opt/miniconda3/envs/dispersant_basf/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "pal(gps, X_train.values, y_train.values, X_test.values,y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dispersant_basf] *",
   "language": "python",
   "name": "conda-env-dispersant_basf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
