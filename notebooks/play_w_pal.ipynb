{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the PAL algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something interesting: https://github.com/VitoChan1/PAL-on-Adder-DSE/blob/master/PAL.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the paper (PAL: An Active Learning Approach to the Multi-Objective Optimization Problem form the Puschel group at ETH)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* error bounds based on hypervolume error\n",
    "* response surface methods for unevaluated designs. Best so far: PareEGO also uses GP\n",
    "* scalariztion: without assumptions like convexity not all solutions can be recovered\n",
    "\n",
    "* uncertainity captured with hyperparameter, there is some scaling parameter beta that determines which fraction of the variance is used. \n",
    "* then classified as pareto optimal if the pessimistic bound is not dominated by the optimistic outcome of any other point\n",
    "* if the optimisitc bound is dominated by the pessimistic bound of any other point, then not pareto optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pareto_optimal(scores: np.array) -> np.array:\n",
    "    size = scores.shape[0]\n",
    "    ids = np.arange(size)\n",
    "    pareto_front = np.ones(size, dtype=bool)\n",
    "        for j in range(size):\n",
    "            # Check if our 'i' point is dominated by our 'j' point\n",
    "            if all(scores[j] >= scores[i]) and any(scores[j] > scores[i]):\n",
    "                # j dominates i. Label 'i' point as dominant\n",
    "                pareto_front[i] = 0\n",
    "                break\n",
    "    # Return ids of pareto front\n",
    "    return ids[pareto_front]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use PyGMO as they have spent more thought into how to implement this: \n",
    "\n",
    "https://esa.github.io/pygmo/documentation/hypervolume.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmo as pg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypervolume(pareto_front: np.array, reference_vector: np.array) -> float: \n",
    "    hyp = pg.hypervolume(pareto_front) \n",
    "    volume = hyp.compute(reference_vector) # uses 'auto' algorithm\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dispersant_basf] *",
   "language": "python",
   "name": "conda-env-dispersant_basf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
