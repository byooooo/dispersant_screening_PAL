{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from dispersant_screener.utils import get_maxmin_samples, get_hypervolume, read_pickle, get_random_exploration_bl\n",
    "from dispersant_screener.definitions import FEATURES\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from glob import glob \n",
    "import os\n",
    "\n",
    "DATADIR = '../data'\n",
    "from functools import partial\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "COLORS = [\n",
    "    \"#ffbe0b\", \n",
    "    \"#fb5607\", \n",
    "    \"#ff006e\",\n",
    "    \"#3a86ff\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(n_samples, label_scaling: bool = False):\n",
    "    \"\"\"Take in Brian's data and spit out some numpy arrays for the PAL\"\"\"\n",
    "    df_full_factorial_feat = pd.read_csv(os.path.join(DATADIR, 'new_features_full_random.csv'))[FEATURES].values\n",
    "    a2 = pd.read_csv(os.path.join(DATADIR, 'b1-b21_random_virial_large_new.csv'))['A2_normalized'].values\n",
    "    deltaGMax = pd.read_csv(os.path.join(DATADIR, 'b1-b21_random_virial_large_new.csv'))['A2_normalized'].values  # pylint:disable=unused-variable\n",
    "    gibbs = pd.read_csv(os.path.join(DATADIR, 'b1-b21_random_deltaG.csv'))['deltaGmin'].values * (-1)\n",
    "    gibbs_max = pd.read_csv(os.path.join(DATADIR, 'b1-b21_random_virial_large_new.csv'))['deltaGmax'].values\n",
    "    force_max = pd.read_csv(os.path.join(DATADIR, 'b1-b21_random_virial_large_fit2.csv'))['F_repel_max'].values  # pylint:disable=unused-variable\n",
    "    rg = pd.read_csv(os.path.join(DATADIR, 'rg_results.csv'))['Rg'].values\n",
    "    y = np.hstack([rg.reshape(-1, 1), gibbs.reshape(-1, 1), gibbs_max.reshape(-1, 1)])\n",
    "    assert len(df_full_factorial_feat) == len(a2) == len(gibbs) == len(y)\n",
    "\n",
    "    feat_scaler = StandardScaler()\n",
    "    X = feat_scaler.fit_transform(df_full_factorial_feat)\n",
    "\n",
    "    if label_scaling:\n",
    "        label_scaler = MinMaxScaler()\n",
    "        y = label_scaler.fit_transform(y)\n",
    "\n",
    "    #greedy_indices = get_maxmin_samples(X, n_samples)\n",
    "\n",
    "    return X, y#, greedy_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_explorations = []\n",
    "\n",
    "for i in range(5000):\n",
    "    hv_random = get_random_exploration_bl(y)\n",
    "    random_explorations.append(hv_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('random_exploration.npy', random_explorations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
